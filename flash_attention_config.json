{
    "experiment_type": "FLASH_ATTENTION",
    "installation_config": {
        "method": "pip_install",
        "package": "flash-attn",
        "no_build_isolation": true,
        "timeout_minutes": 30
    },
    "environment_variables": {
        "FLASH_ATTENTION_SKIP_CUDA_BUILD": "0",
        "FLASH_ATTENTION_FORCE_BUILD": "1",
        "TORCH_CUDA_ARCH_LIST": "8.6+PTX",
        "MAX_JOBS": "6"
    },
    "training_config": {
        "epochs": 100,
        "batch": 8,
        "imgsz": 640,
        "device": "cuda:0",
        "workers": 6,
        "optimizer": "AdamW",
        "lr0": 0.001,
        "amp": true,
        "cache": false,
        "patience": 30,
        "save_period": 5
    }
}