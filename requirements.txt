# Core dependencies for SDPA vs Flash Attention experiments
torch>=2.2.0
torchvision>=0.17.0
ultralytics>=8.3.156
numpy>=1.26.4
pandas>=2.3.0
matplotlib>=3.10.0
seaborn>=0.13.2
pillow>=10.0.0
opencv-python>=4.9.0.80
psutil>=5.9.8
tqdm>=4.67.1
scipy>=1.13.0
scikit-learn>=1.3.0

# Optional: Flash Attention (requires CUDA compilation)
# flash-attn>=2.7.0  # Uncomment if you want to test Flash Attention

# Dataset tools
roboflow>=1.1.0
pycocotools>=2.0.7

# Experiment tracking
tensorboard>=2.15.0
wandb>=0.16.0  # Optional